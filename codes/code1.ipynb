{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./dataset/north_korea_missile_test_database.csv\")\n",
    "y = df[\"Missile Name\"]\n",
    "x = df.drop(\"Missile Name\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=31 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=31 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./dataset/file_pe_headers.csv\", sep= \",\")\n",
    "x = data.drop([\"Name\", \"Malware\"], axis = 1).to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_standardized = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.16886290e-01, -7.15480741e-02,  3.16916194e+00, ...,\n",
       "         4.19841438e-15, -1.31839076e-15,  8.48434216e-15],\n",
       "       [-3.04037254e-01, -1.28517084e-01, -2.40204566e-01, ...,\n",
       "         2.17976611e-15, -5.82238596e-16,  5.25822437e-15],\n",
       "       [-3.07312786e-01, -1.31296697e-01, -1.06253036e+00, ...,\n",
       "         5.31012022e-15, -1.51451367e-15,  1.07280536e-14],\n",
       "       ...,\n",
       "       [ 6.24269798e-01, -5.07561736e-02,  6.13792253e-01, ...,\n",
       "         9.66003788e-16,  1.45855180e-16,  2.10394185e-15],\n",
       "       [-2.54202111e-01, -2.25874904e-02,  1.53710266e-01, ...,\n",
       "        -1.73023681e-15,  4.55172091e-16, -3.06215581e-15],\n",
       "       [-4.06052243e-01, -4.98937892e-02, -3.67792815e-02, ...,\n",
       "        -4.65902801e-15,  8.02147210e-16, -8.65803117e-15]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit_transform(x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13714096e-01 6.04526312e-02 5.35847638e-02 4.95286930e-02\n",
      " 4.08242868e-02 3.43687925e-02 3.32004002e-02 3.01112226e-02\n",
      " 2.86901095e-02 2.81624164e-02 2.54807940e-02 2.38845548e-02\n",
      " 2.22696648e-02 2.05755591e-02 1.82485433e-02 1.73648310e-02\n",
      " 1.66649078e-02 1.63647194e-02 1.52683994e-02 1.46357930e-02\n",
      " 1.45790542e-02 1.45535760e-02 1.44699413e-02 1.44154480e-02\n",
      " 1.42948516e-02 1.39221004e-02 1.35338124e-02 1.33766277e-02\n",
      " 1.32896667e-02 1.23472302e-02 1.20507834e-02 1.15452214e-02\n",
      " 1.13731313e-02 1.10939084e-02 1.07062189e-02 1.01649154e-02\n",
      " 9.90148375e-03 9.61478385e-03 9.17627698e-03 9.04802544e-03\n",
      " 8.66332999e-03 6.94752252e-03 6.84216033e-03 6.48244001e-03\n",
      " 5.95005317e-03 5.91335216e-03 5.41615029e-03 5.10640740e-03\n",
      " 4.83543074e-03 4.45888820e-03 4.29104432e-03 3.82076025e-03\n",
      " 3.79864324e-03 3.24146447e-03 3.18558571e-03 2.67004617e-03\n",
      " 2.03201471e-03 1.73591476e-03 1.65758475e-03 1.56708821e-03\n",
      " 1.38839592e-03 1.20694096e-03 8.20896559e-04 6.92520065e-04\n",
      " 2.79632267e-04 1.36614783e-04 6.56001071e-06 3.22441346e-07\n",
      " 1.26534208e-10 3.32116793e-18 1.53157505e-18 1.20835773e-18\n",
      " 5.00052024e-19 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains : used for user behavious analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/airport.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "N = 100\n",
    " \n",
    "review_subset = df[\"content\"][0:N]\n",
    "text = \"\".join(chain.from_iterable(review_subset))\n",
    "markov_chain_model = markovify.Text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally on arrival at destination - no baggage - more comfortable better access to the passport control from our flight was closing.We transferred from a virtually unheated part of the airport from Bucharest Centre should be a regional hub airport.\n",
      "Once outside I recommend you press on through the formalities the shops or catering so can't comment there.\n",
      "The airport taxis are a customs airport officer to leave the plane.\n",
      "Terrible experience will avoid like the plague.I am always amazed about the plane across the tarmac Â± 100 metres.\n",
      "Check in for quite some time to get to security was faced with a good clean modern and efficient airport - a pleasant surprise.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(markov_chain_model.make_sentence())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also had to argue for quite a lot of hand luggage and I couldn't find a solution to this excuse of an airport.\n",
      "At least a 400m queue to reach airline on last call had been in after 60 years of travelling all over the world.\n",
      "The train connection is excellent but the terminal passengers walk to the most inefficient airports.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(markov_chain_model.make_short_sentence(140))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
